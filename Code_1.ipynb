{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import lib cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kieu Trung Ha\\Desktop\\Key-Frames-Extraction-from-Video\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import os \n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate caption for image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model \n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\", torch_dtype=torch.float16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of folder keyframes to generate caption \n",
    "keyframes_folder_path = r'C:\\Users\\Kieu Trung Ha\\Desktop\\AI Challenge\\data_raw\\keyframes\\keyframes'\n",
    "map_keyframes_path = r'C:\\Users\\Kieu Trung Ha\\Desktop\\AI Challenge\\data_raw\\map-keyframes'\n",
    "folder_save_csv = r'C:\\Users\\Kieu Trung Ha\\Desktop\\AI Challenge\\data_raw\\map-keyframes-caption'\n",
    "\n",
    "list_keyframes_path = os.listdir(keyframes_folder_path)\n",
    "print(list_keyframes_path[120:123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of folder keyframes to generate caption \n",
    "keyframes_folder_path = r'C:\\Users\\Kieu Trung Ha\\Desktop\\AI Challenge\\data_raw\\keyframes\\keyframes'\n",
    "map_keyframes_path = r'C:\\Users\\Kieu Trung Ha\\Desktop\\AI Challenge\\data_raw\\map-keyframes'\n",
    "folder_save_csv = r'C:\\Users\\Kieu Trung Ha\\Desktop\\AI Challenge\\data_raw\\map-keyframes-caption'\n",
    "\n",
    "list_keyframes_path = os.listdir(keyframes_folder_path)\n",
    "\n",
    "for folder in list_keyframes_path[120:123]: \n",
    "    list_image = os.listdir(os.path.join(keyframes_folder_path, folder))\n",
    "    \n",
    "    # khởi tại list caption do model generate ra \n",
    "    list_caption = []\n",
    "    \n",
    "    # generate caption \n",
    "    for img_name in list_image: \n",
    "        img_path = os.path.join(os.path.join(keyframes_folder_path, folder), img_name)\n",
    "        \n",
    "        # đọc ảnh và chuyển về rgb\n",
    "        raw_image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        inputs = processor(raw_image, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "\n",
    "        out = model.generate(**inputs)\n",
    "        \n",
    "        list_caption.append(processor.decode(out[0], skip_special_tokens=True))\n",
    "        \n",
    "    # đọc tệp csv thành 1 dataframe \n",
    "    df = pd.read_csv(os.path.join(map_keyframes_path, folder+'.csv'))\n",
    "    \n",
    "    # thêm cột caption vào dataframe\n",
    "    df['Caption'] = list_caption\n",
    "\n",
    "    # Lưu DataFrame vào tệp CSV đã cập nhật\n",
    "    df.to_csv(folder+'_caption.csv', index=False)\n",
    "    \n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xử lý Duplicate keyframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# đầu vào là link của folder keyframes và tên của file map-keyframes\n",
    "def filter_duplicate(keyframes_folder_path, map_keyframes_caption_folder_path):\n",
    "    # get list name of images \n",
    "    list_img = os.listdir(keyframes_folder_path)\n",
    "\n",
    "    # khởi tạo mảng trống để lưu trữ biểu đồ histogram \n",
    "    arr = np.empty((0, 1944), int)\n",
    "\n",
    "    # khởi tạo dictionary để lưu trữ khung hình dưới dạng mảng \n",
    "    D = dict()\n",
    "\n",
    "    for index, i in enumerate(list_img): \n",
    "        img_bgr = cv2.imread(os.path.join(keyframes_folder_path, i))\n",
    "        # convert image from BGR to RGB \n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # lưu trữ ảnh dưới dạng mảng \n",
    "        D[index] = img_rgb\n",
    "        \n",
    "        # chia khung hình thành các khối 3*3 tổng có 9 blocks\n",
    "        height, width, channels = img_rgb.shape\n",
    "        \n",
    "        # kích thước của mỗi block\n",
    "        if height % 3 == 0:\n",
    "            h_chunk = int(height/3)\n",
    "        else:\n",
    "            h_chunk = int(height/3) + 1\n",
    "\n",
    "        if width % 3 == 0:\n",
    "            w_chunk = int(width/3)\n",
    "        else:\n",
    "            w_chunk = int(width/3) + 1\n",
    "            \n",
    "        h=0\n",
    "        w=0 \n",
    "        feature_vector = []\n",
    "        for a in range(1,4):\n",
    "            h_window = h_chunk*a\n",
    "            for b in range(1,4):\n",
    "                frame = img_rgb[h : h_window, w : w_chunk*b , :]\n",
    "                \"\"\"\n",
    "                    tìm histogram cho ảnh, [0, 1, 2] là danh sách  các kênh màu mà histogram được tính toán \n",
    "                    None: giá trị mask \n",
    "                    [6, 6, 6] là kích thước của histogram, tức là mỗi kênh màu, histogram sẽ tính toán 6 bin \n",
    "                    [0, 256, 0, 256, 0, 256] đây là phạm vi giá trị của các kênh màu\n",
    "                \"\"\"\n",
    "                hist = cv2.calcHist(frame, [0, 1, 2], None, [6, 6, 6], [0, 256, 0, 256, 0, 256])  \n",
    "                hist1= hist.flatten()  # flatten the hist to one-dimensinal vector \n",
    "                feature_vector += list(hist1)\n",
    "                w = w_chunk*b\n",
    "                \n",
    "            h = h_chunk*a\n",
    "            w= 0\n",
    "        \n",
    "        arr =np.vstack((arr, feature_vector ))\n",
    "        \n",
    "    final_arr = arr.transpose() #transposing so that i will have all frames in columns i.e M*N dimensional matrix \n",
    "    #where M is 1944 and N is number of frames\n",
    "    \n",
    "    # hàm csc_matrix là một hàm trong thư viện scipy sử dụng để tạo 1 ma trận trong định dạng Compressed Sparse Column \n",
    "    # định dạng CSC là một định dạng lưu trữ ma trận thưa (sparse matrix) trong đó các phần tử khác không được lưu trữ kèm index của chúng\n",
    "    A = csc_matrix(final_arr, dtype=float)\n",
    "\n",
    "    # svds là hàm dùng để phân tích giá trị riêng (singular value decomposition - SVD) trên ma trận thưa (sparse matrix), giúp phân tích một ma trận thành các thành phần như giá trị riêng, vector riêng và các giá trị đặc trưng khác \n",
    "    # top 63 singular values from 76082 to 508\n",
    "    # u là ma trận các vector riêng trái \n",
    "    # s là một mảng chứa các giá trị riêng \n",
    "    # vt là ma trận chứa các vector riêng phải \n",
    "    u, s, vt = svds(A, k = 63)\n",
    "\n",
    "    # trả về ma trận chuyển vị của vt\n",
    "    v1_t = vt.transpose()\n",
    "\n",
    "    # np.diag(s) tạo ra 1 ma trận đường chéo cho mảng s, các giá trị nằm trên đường chéo bằng với s, còn lại bằng 0 \n",
    "    # các cột trong ma trận vt là các dữ liệu histogram được chiếu lên cơ sở trực giao\n",
    "    projections = v1_t @ np.diag(s) \n",
    "    #formed by vectors of the left singular matrix u .The coordinates of the frames in this space are given by v1_t @ np.diag(s)\n",
    "    #So we can see that , now we need only 63 dimensions to represent each column/frame \n",
    "    \n",
    "    f = projections \n",
    "\n",
    "    # khởi tạo 1 dictionary lưu trữ các frames trong respective cluster \n",
    "    C = dict()\n",
    "\n",
    "    # khởi tạo list các index của keyframes trùng nhau trong 1 scence\n",
    "    list_keyframes = []\n",
    "\n",
    "    # tạo ra 1 dictionary chứa 236 mảng kích thước 63 \n",
    "    for i in range(f.shape[0]): \n",
    "        C[i] = np.empty((0, 63), int)\n",
    "        \n",
    "    # khởi tạo frame đầu tiên trong cụm đầu tiên \n",
    "    C[0] = np.vstack((C[0], f[0]))\n",
    "    # C[0] = np.vstack((C[0], f[1]))\n",
    "\n",
    "    # khởi tạo dictionary để lưu trữ centroids của mỗi cluster \n",
    "    E = dict()\n",
    "    for i in range(projections.shape[0]):\n",
    "        E[i] = np.empty((0, 63), int)\n",
    "        \n",
    "    E[0] = np.mean(C[0], axis=0)\n",
    "\n",
    "    count = 0 \n",
    "    for i in range(1, f.shape[0]):\n",
    "        similarity = np.dot(f[i], E[count])/( (np.dot(f[i],f[i]) **.5) * (np.dot(E[count], E[count]) ** .5))\n",
    "        \n",
    "        if similarity < 0.9: \n",
    "            count+=1\n",
    "            C[count] = np.vstack((C[count], f[i]))\n",
    "            E[count] = np.mean(C[count], axis=0)   \n",
    "        else: \n",
    "            C[count] = np.vstack((C[count], f[i])) \n",
    "            E[count] = np.mean(C[count], axis=0)  \n",
    "            list_keyframes.append(i)\n",
    "\n",
    "    # xóa file keyframe và row chứa keyframes trùng nhau\n",
    "    kfcaption_dataframe = pd.read_csv(map_keyframes_caption_folder_path)\n",
    "    \n",
    "    for id, file_path in enumerate(os.listdir(keyframes_folder_path)):\n",
    "        if id in list_keyframes:\n",
    "            # xóa keyframe trong folder keyframes\n",
    "            os.remove(os.path.join(keyframes_folder_path, file_path))\n",
    "\n",
    "    \n",
    "    # xóa row keyframes bị trùng \n",
    "    kfcaption_dataframe = kfcaption_dataframe.drop(list_keyframes).reset_index(drop=True)\n",
    "    \n",
    "    # thêm cột độ dài của sence \n",
    "    kfcaption_dataframe['length sence'] = kfcaption_dataframe['frame_idx'].diff().shift(-1)\n",
    "    \n",
    "    kfcaption_dataframe['Video'] = keyframes_folder_path.split('\\\\')[-1]\n",
    "    \n",
    "    kfcaption_dataframe.to_csv(map_keyframes_caption_folder_path, index=False) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lọc keyframes trùng nhau và xóa row cho tất cả các folder keyframes, sau đó thêm 1 cột tên video và cột chứa độ dài frame của keyframes đó\n",
    "keyframes_folder_path = r'C:\\Users\\Kieu Trung Ha\\Desktop\\AI Challenge\\data_raw\\keyframes'\n",
    "map_keyframes_caption_path = r'C:\\Users\\Kieu Trung Ha\\Desktop\\AI Challenge\\data_raw\\map-keyframes-caption'\n",
    "\n",
    "list_keyframes_folder = os.listdir(keyframes_folder_path)\n",
    "\n",
    "for folder in list_keyframes_folder:\n",
    "    folder_path = os.path.join(keyframes_folder_path, folder)\n",
    "    file_mapkf_caption_path = os.path.join(map_keyframes_caption_path, folder + '_caption.csv')\n",
    "    \n",
    "    filter_duplicate(folder_path, file_mapkf_caption_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nối tất cả file csv vào 1 file duy nhất\n",
    "map_keyframes_caption_path = r'C:\\Users\\Kieu Trung Ha\\Desktop\\AI Challenge\\data_raw\\map-keyframes-caption'\n",
    "\n",
    "# Danh sách để lưu các DataFrame từ các tệp CSV\n",
    "dataframes = []\n",
    "\n",
    "# Lặp qua từng tệp CSV\n",
    "for file in os.listdir(map_keyframes_caption_path):\n",
    "    # Đọc tệp CSV vào DataFrame\n",
    "    df = pd.read_csv(os.path.join(map_keyframes_caption_path, file))\n",
    "    \n",
    "    # Xóa cột \"n\"\n",
    "    df = df.drop(\"n\", axis=1)\n",
    "    \n",
    "    # Thêm DataFrame vào danh sách\n",
    "    dataframes.append(df)\n",
    "    \n",
    "# Nối các DataFrame thành một DataFrame duy nhất\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Ghi DataFrame duy nhất vào tệp CSV\n",
    "merged_df.to_csv('summary_map_keyframes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đổi tên các file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_keyframes_caption_path = r'C:\\Users\\Kieu Trung Ha\\Desktop\\AI Challenge\\data_raw\\map-keyframes-caption'\n",
    "\n",
    "list_mapkf_cap_path = os.listdir(map_keyframes_caption_path)\n",
    "\n",
    "# đổi tên các file cùng định dạng\n",
    "for file_path in list_mapkf_cap_path:\n",
    "    old_name = os.path.join(map_keyframes_caption_path, file_path)\n",
    "    \n",
    "    if '_caption' not in file_path: \n",
    "        new_name = os.path.join(map_keyframes_caption_path, file_path.split('.')[0] + '_caption.csv')\n",
    "\n",
    "        # Sử dụng hàm rename() để đổi tên file\n",
    "        os.rename(old_name, new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truy xuất "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73044\n"
     ]
    }
   ],
   "source": [
    "# thêm 1 column chứa tên các img tương ứng với row \n",
    "summary_map_kf = pd.read_csv('summary_map_keyframes.csv')\n",
    "\n",
    "list_image_name = []\n",
    "\n",
    "# lặp qua tất cả các folder keyframes lấy ra tên của ảnh sau đó thêm vào list tên image\n",
    "keyframes_folder_path = r'C:\\Users\\Kieu Trung Ha\\Desktop\\AI Challenge\\data_raw\\keyframes'\n",
    "for folder in os.listdir(keyframes_folder_path):\n",
    "    list_img_name = os.listdir(os.path.join(keyframes_folder_path, folder))\n",
    "    list_image_name.append(list_img_name)\n",
    "    \n",
    "flattened_list = [item for sublist in list_image_name for item in sublist]\n",
    "print(len(flattened_list))\n",
    "\n",
    "# tạo thêm 1 columns chứa tên ảnh \n",
    "summary_map_kf['img_name'] = flattened_list\n",
    "\n",
    "summary_map_kf.to_csv('summary_map_keyframes_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Kieu Trung\n",
      "[nltk_data]     Ha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Kieu Trung\n",
      "[nltk_data]     Ha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')  # Tải xuống tài nguyên stopwords\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import csv \n",
    "\n",
    "# Thời điểm bắt đầu\n",
    "start_time = time.time()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tách từ và loại bỏ stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "def calculate_cosine_similarity(text1, text2):\n",
    "    # Tiền xử lý và biểu diễn hai đoạn văn bản thành các vectơ\n",
    "    tokens1 = preprocess_text(text1)\n",
    "    tokens2 = preprocess_text(text2)\n",
    "    all_tokens = list(set(tokens1 + tokens2))\n",
    "    vector1 = [tokens1.count(token) for token in all_tokens]\n",
    "    vector2 = [tokens2.count(token) for token in all_tokens]\n",
    "\n",
    "    # Tính toán cosine similarity\n",
    "    dot_product = sum(i*j for i, j in zip(vector1, vector2))\n",
    "    magnitude1 = sum(i**2 for i in vector1) ** 0.5\n",
    "    magnitude2 = sum(i**2 for i in vector2) ** 0.5\n",
    "    cosine_similarity = dot_product / (magnitude1 * magnitude2)\n",
    "    return cosine_similarity\n",
    "\n",
    "def cut_video(input_path, output_path, start_frame, end_frame):\n",
    "    # Tính toán thời gian bắt đầu và kết thúc dựa trên số khung hình trên giây\n",
    "    duration = end_frame - start_frame\n",
    "    start_time = start_frame / 25\n",
    "    end_time = end_frame / 25\n",
    "\n",
    "    # Cắt video con từ video ban đầu\n",
    "    ffmpeg_extract_subclip(input_path, start_time, end_time, targetname=output_path)\n",
    "\n",
    "def query(input_text, path_csv, keyframes_folder_path, video_folder_path, results_folder_path, time_dp=False) :\n",
    "    df = pd.read_csv(path_csv)\n",
    "    cosine_sim = []\n",
    "    # Duyệt qua từng tệp tin trong thư mục\n",
    "    for cap in df['Caption'] :\n",
    "        cosine_sim.append(calculate_cosine_similarity(input_text, cap))\n",
    "\n",
    "    # Sử dụng list comprehension để tạo ra một list các cặp (giá trị, số thứ tự)\n",
    "    value_index_pairs = [(value, index) for index, value in enumerate(cosine_sim)]\n",
    "\n",
    "    # Sắp xếp list các cặp theo giá trị giảm dần\n",
    "    value_index_pairs.sort(reverse=True)\n",
    "    \n",
    "    # lấy ra list path của video và số frame sence tương ứng\n",
    "    rs = []\n",
    "    \n",
    "    # In ra số thứ tự của 10 giá trị lớn nhất\n",
    "    for value, index in value_index_pairs[:10]:\n",
    "        # print(\"Giá trị:\", value, \" - Số thứ tự:\", index , \" Video :\" ,  df.loc[index, 'Video'], \" Frame :\" , df.loc[index, 'frame_idx'])\n",
    "        img_name = df.loc[index, 'img_name']\n",
    "        folder_name = df.loc[index, 'Video']\n",
    "        leng_sence = df.loc[index, 'length sence']\n",
    "        img_path = os.path.join(keyframes_folder_path, os.path.join(folder_name, img_name))\n",
    "        # result \n",
    "        result = []\n",
    "        result.append(folder_name)\n",
    "        result.append(leng_sence)\n",
    "        result.append(df.loc[index, 'frame_idx'])\n",
    "        result.append(img_name)\n",
    "        rs.append(result)\n",
    "        \n",
    "        # print(img_path)\n",
    "        # img = cv2.imread(img_path)\n",
    "        # cv2.imshow(img_name, img)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "    if time_dp == True: \n",
    "        # Thời điểm kết thúc\n",
    "        end_time = time.time()\n",
    "        # Tính thời gian chạy\n",
    "        execution_time = end_time - start_time\n",
    "        print(\"Thời gian chạy:\", execution_time, \"giây\")\n",
    "        \n",
    "    # cut video và lưu vào folder kết quả\n",
    "    for id, result in enumerate(rs):\n",
    "        input_path = os.path.join(video_folder_path, result[0]+'.mp4')\n",
    "        start_keyframe = int(result[2])\n",
    "        leng_sence = int(result[1]) \n",
    "        end_keyframe = int(start_keyframe + leng_sence)\n",
    "        output_path = os.path.join(results_folder_path, 'rank_'+str(id)+'_'+result[0]+'.mp4')\n",
    "        \n",
    "        cut_video(input_path, output_path, start_keyframe, end_keyframe)\n",
    "    \n",
    "        result_file_path = r'result.csv'\n",
    "        # kiểm tra xem tệp tin csv tồn tại hay không \n",
    "        if not os.path.isfile(result_file_path): \n",
    "            # nếu tập tin không tồn tại, tạo tập tin mới \n",
    "            with open(result_file_path, 'w', newline='') as file: \n",
    "                writer = csv.writer(file)\n",
    "                # thêm các tiêu đề cầ thiết \n",
    "                writer.writerow(['query', 'video', 'keyframe', 'length', 'rank'])\n",
    "                \n",
    "        with open(result_file_path, 'a', newline='') as file: \n",
    "            writer = csv.writer(file)\n",
    "            # thêm các kết quả mới vào dòng cuối cùng \n",
    "            writer.writerow([input_text, result[0], result[3], result[1], id])\n",
    "    \n",
    "    # return rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "video_folder_path = r'C:\\Users\\Kieu Trung Ha\\Desktop\\AI Challenge\\data_raw\\video\\video'\n",
    "results_folder_path = r'C:\\Users\\Kieu Trung Ha\\Desktop\\Key-Frames-Extraction-from-Video\\results'\n",
    "keyframes_folder_path = r'C:\\Users\\Kieu Trung Ha\\Desktop\\AI Challenge\\data_raw\\keyframes'\n",
    "path_csv = r'summary_map_keyframes_final.csv'\n",
    "\n",
    "result = query(\"dairy cows are eating\", path_csv, keyframes_folder_path, video_folder_path, results_folder_path, time_dp=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear folder video kết quả \n",
    "folder_path = r'C:\\Users\\Kieu Trung Ha\\Desktop\\Key-Frames-Extraction-from-Video\\results'  # Đường dẫn đến thư mục của bạn\n",
    "\n",
    "# Lặp qua tất cả các tệp tin trong thư mục và xóa chúng\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
